\documentclass[10pt,twocolumn]{article}
\usepackage[british]{babel}
%\usepackage[utf8]{inputenc}
\usepackage[margin=2.25cm]{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{subcaption}
\usepackage{float}
\usepackage{hyperref}
\usepackage[table,xcdraw]{xcolor}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage[section]{placeins}

%argmin, argmax
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\diag}{diag}

\newcommand{\mmatrix}[1]{\boldsymbol{#1}}
\newcommand{\mvec}[1]{\boldsymbol{#1}}

\graphicspath{ {./images/} }

\usepackage{pgfplots}
\pgfplotsset{compat=1.16}

\usepackage{titlesec}
\titleformat{\section}
{\normalfont\Large\bfseries}{Group~\thesection.}{1em}{}

%\titleformat*{\subsection}{\normalsize\bfseries} % make subsection title smaller
\titleformat{\subsection}
{\normalfont\normalsize\bfseries}{\thesubsection}{.5em}{}

\renewcommand\thesubsection{\Roman{section}. \alph{subsection})}
\renewcommand{\thesection}{\Roman{section}}

\newcommand{\footurl}[1]{\footnote{\url{#1}}}
\newcommand{\todo}[1]{\textcolor{blue}{[\textbf{TODO: #1}]} } 
\usepackage[en-GB]{datetime2}   % for pretty date
\DTMlangsetup[en-GB]{ord=raise} % for pretty date

\usepackage{tikz}
\usepackage{tikz-qtree}
\usetikzlibrary{matrix}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{arrows,automata}
\colorlet{pinkyred}{pink!50!red}

\usepackage{amsmath}
\DeclareMathOperator{\score}{score}

\setlength{\columnsep}{2em}

\title{Report for LAB6: Omics Applications \\
\Large{Bioinformatics}}
\author{ Ricardo Brancas    \\ 83557
    \and Margarida Ferreira \\ 80832
    \and Felipe Gorostiaga  \\ 95383
    \and Benedict Schubert  \\ 95034}

\date{\today}

\begin{document}
\maketitle

<<include=FALSE,cache=FALSE>>=
library(ggplot2)
library(RColorBrewer)
library(edgeR)
library(stringr)
library(ggpubr)
library(survival)
library(ggfortify)
library(knitr)
library(tidyr)
library(plotROC)
library(e1071)
library(caTools)
library(MLmetrics)
library(class)
library(caret)
library(reshape2)
library(ensr)
opts_chunk$set(echo=FALSE)
options(digits=4)
@

<<echo=FALSE,cache=TRUE,cache.lazy=FALSE>>=
read_counts = read.csv('TCGA_BRCA_Gene_ReadCounts.txt', sep='\t', header=TRUE, row.names = 1)
counts_histogram = data.frame(counts=colSums(read_counts))
counts_comparison = read.csv('outputs/counts_comparison.csv', sep=',', header=TRUE)
annotations = read.delim('TCGA_BRCA_ClinicalAnnotation.txt', header=TRUE, row.names=1)
rownames(annotations) = str_replace(str_replace(rownames(annotations), '-', '.'), '-', '.')

ESR1 = t(read_counts[c("ESR1"),])
ESR2 = t(read_counts[c("ESR2"),])
PGR = t(read_counts[c("PGR"),])[,1]
ERBB2 = t(read_counts[c("ERBB2"),])

groups = as.numeric(substr(colnames(read_counts), nchar(colnames(read_counts))-1, nchar(colnames(read_counts))-1))

Tissue <- factor(groups)
Patient <- factor(substr(colnames(read_counts), 0, 12))
Estrogen <- addNA(annotations$Estrogen.Receptor[Patient])
Estrogen_bin <- dplyr::recode_factor(Estrogen, "indeterminate" = NA_character_)
Progesterone <- addNA(annotations$Progesterone.Receptor[Patient])
Progesterone_bin <- dplyr::recode_factor(Progesterone, "indeterminate" = NA_character_)
HER2 <- addNA(annotations$HER2[Patient])
HER2_bin <- dplyr::recode_factor(HER2, "indeterminate" = NA_character_)
HER2_bin <- dplyr::recode_factor(HER2_bin, "equivocal" = NA_character_)
HER2_bin <- dplyr::recode_factor(HER2_bin, "unknown" = NA_character_)
Status <- annotations$Vital.status[Patient]
PAM50 <- annotations$PAM50[Patient]
LastFollowUp <- annotations$Days.to.last.follow.up[Patient]
DaysToDeath <- annotations$Days.to.death[Patient]
Menopause <- annotations$Menopausal.status[Patient]
Ethnicity <- annotations$Ethnicity[Patient]

data_g1 <- read_counts %>% gather() %>% extract(key, c("tissue"), regex="([01]).$", remove=FALSE, convert=TRUE)
data_g1$tissue = factor(data_g1$tissue)

data_g3 <- data.frame(ESR1, ESR2, PGR, ERBB2, Estrogen, Progesterone, HER2)

@


%paired end read -> reason why we have 2 FASTQ files.
\section{}

\subsection{Quality assessment of FASTQ} %1a)
In figure~\ref{fig:sequence-quality} we present the per base sequence quality graphs obtained using the tool \textsc{FastQC}. The sequences have reasonably good quality scores, although there is some disparity between them. In particular the first sequence has slightly better quality than the second one, which is something one should be aware of.

\begin{figure}[ht]
     \centering
     \begin{subfigure}[b]{0.9\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{outputs/quality1.png}
         \caption{Quality graph for raw sequence 1.}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.9\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{outputs/quality2.png}
         \caption{Quality graph for raw sequence 2.}
     \end{subfigure}
        \caption{Quality graphs for the raw sequences, as obtained in \textsc{FastQC}.}
        \label{fig:sequence-quality}
\end{figure}

\subsection{Estimated gene expression vs. provided read counts} %1b)
We chose to use the aligner \textsc{Kallisto}, together with the annotated human transcriptome from Ensembl \footurl{ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz}.
We chose the cDNA sequences, as advised in the Kallisto FAQ \footurl{https://pachterlab.github.io/kallisto/faq}.

To compare the transcript expression with the gene expression counts given, we downloaded a mapping from the Ensembl transcript identifiers to gene names. We used  Ensembl Biomart \footurl{http://www.ensembl.org/biomart/martview/a797838aa8255de1efa6fb6d11322eb5} to get this mapping. We then took the transcript count estimates and the mapping and created a summarised table containing the total estimated number of reads for each gene. Finally, comparing this table with the read count table we were given, results in the graph in figure~\ref{fig:count-comparison}. Figure~\ref{fig:count-comparison}a shows all the estimated and provided read counts plotted against each other: each black mark represents a gene, the value on the y-axis is the provided read count, while the value on the x axis is the estimated read count; therefore, the closer a mark is to the \(y=x\) line, the better the estimation. Analysing this graph, we can see that most genes are correctly estimated, as most marks lie within the \(y=x\) line. Most outliers are from read counts of 0 which most likely represents a mismatch between the transcript identifiers and the gene names. In Figure~\ref{fig:count-comparison}b we show the same data, this time plotted in logarithmic scale so the values are more easily seen. Note that, in order to plot in a logarithmic scale, all the zero-valued read counts must be removed. In this plot we can again see that most of the estimates are accurate, even though there are a few outliers. We can also see that it appears that the higher the read count the better the estimation. This however is no true: what we are seeing is a result of the logarithmic scale: the errors are of the same order of magnitude, but since the scale is much larger, they seem smaller when compared to the actual read count values.

<<count-comparison, fig.pos='ht', fig.width=4, fig.height=3, fig.ncol=1, fig.align='center', fig.cap="Comparison between the estimated counts and the provided values.", fig.subcap=c("", "Log-log plot after removing 0 values.")>>=
ggplot(counts_comparison, aes(x=est, y=target)) + geom_point(color=brewer.pal(3, "Dark2")[1]) + geom_abline(color=brewer.pal(3, "Dark2")[2]) + theme_classic()
new_counts <- counts_comparison[which(counts_comparison[c("est")] >= 1), ]
new_counts <- new_counts[which(new_counts[c("target")] >= 1), ]
ggplot(new_counts, aes(x=est, y=target)) + geom_point(color=brewer.pal(3, "Dark2")[1]) + scale_x_log10() + geom_abline(color=brewer.pal(3, "Dark2")[2]) + scale_y_log10() + theme_classic()
@

\section{} % II

\subsection{Read coverage and library complexity} % 2a)
To analyse the read coverage, we created the histogram in figure~\ref{fig:read-coverage}. We can see that the count values range from roughly 40 million to 180 million.
We can also see that most samples have more than 60 million reads, although a very small number has only around 40 million.
This might mean that in these samples lowly expressed genes are below the detection threshold. We can also see that there are a lot more genes with read counts in the 60 to 100 million range than in the rest of the domain, which indicates that we will probably need some kind of normalisation of the data.

<<read-coverage, fig.pos="ht", fig.width=5, fig.asp=1/2, fig.align='center', fig.cap="Read counts histogram.">>=
ggplot(counts_histogram, aes(x=counts)) + ylab("Absolute Frequency") + xlab("#reads") + geom_histogram(color="black", fill="white", bins=20) + theme_classic()
@

Library complexity refers to the number of unique DNA fragments present in a given library. To compute library complexity, we used a sampling-based approach. For each tissue sample, we sampled the genes with probability proportional to the read count of each gene for that patient. In figure~\ref{fig:library-complexity} we plot the library complexities for all samples.
Analysing the figure we can see that, in general, in samples from normal tissues we hit more genes with fewer samples, which means that the genes are more uniformly represented. On the other hand, in deseased tissues, we get a lower percentage of all the detected genes with the same number of samples, showing that the read counts for the genes in deseased tissues is farther from a uniform distribution: there are a few genes with a much higher read count than the others. Finally, there is one outlier, a normal sample, for whom the gene coverage is a lot lower than that of the other samples, for the same number of random samples measured.


<<library-complexity, fig.pos="ht", fig.asp=2/3, fig.align='center', fig.cap="Library complexity plot.", cache=TRUE>>=
# ggplot(data_g1, aes(x = value, group=key, color=tissue)) + stat_ecdf(geom="line") + scale_x_log10() + coord_cartesian(xlim=c(0,2000))

groups = as.numeric(substr(colnames(read_counts), nchar(colnames(read_counts))-1, nchar(colnames(read_counts))-1))
colors <- brewer.pal(3, "Dark2")

sample_n = 16
increment = 16000

list = c()
for (i in 1:sample_n) {
  list = append(list, c(length(unique(sample(rownames(read_counts), size=i*increment, prob=read_counts$TCGA.A1.A0SB.01, replace=TRUE))) / nrow(read_counts)))
}

plot(1:length(list) * increment, unlist(list), type="l", col=alpha(colors[groups[which(colnames(read_counts) == "TCGA.A1.A0SB.01")] + 1], 0.2), ylim=c(0,0.7), xlab="Number of Samples", ylab="Gene Coverage")

first = TRUE
for (person in colnames(read_counts)) {
  if (first) {
    first = FALSE
    next
  }
  list = c()
  for (i in 1:sample_n) {
    list = append(list, c(length(unique(sample(rownames(read_counts), size=i*increment, prob=read_counts[[person]], replace=TRUE))) / nrow(read_counts)))
  }
  lines(1:length(list) * increment, unlist(list), col=alpha(colors[groups[which(colnames(read_counts) == person)] + 1], 0.2), xlab="Number of Samples", ylab="Gene Coverage")
}
legend("bottomright", legend=c("Tumour Sample", "Normal Sample"), col=brewer.pal(3, "Dark2"), fill=brewer.pal(3, "Dark2"), cex=0.8)
@

\subsection{Normalisation of the data} % 2b)
In order to make  gene expression profiles comparable between samples, we normalised the data using the Trimmed Mean of M (TMM) method. Then, we produced a series of plots which help us visualise how the data changed after the normalisation.

First, we plotted the histogram of the normalised read counts, which can be seen in figure~\ref{fig:norm-read-coverage}. We can see a few differences in the distribution of normalised read counts when compared with that of the raw read counts (in figure~\ref{fig:read-coverage}). We can see that there is no longer such an accentuated ``tail'' on the right-side of the histogram (the higher read count values). While in the raw read counts the last bin was accounting for genes with a read count of around 180 million, in the normalised version we no longer have such high values: the last bin has read count of about 170 million read counts. Furthermore, we can identify in the normalised read counts a bimodal distribution: there are 2 peaks in the histogram, at around 75 million and 90 million normalized reads. These could not be seen in the original read count histogram where only one peak was discernible at around 85 million read counts.

<<norm-read-coverage, fig.pos="ht", fig.width=5, fig.asp=1/2, fig.align='center', fig.cap="Read counts histogram.">>=
dge <- DGEList(counts=data.matrix(read_counts))

keep <- filterByExpr(dge)
dge <- dge[keep, , keep.lib.sizes=FALSE]

dge <- calcNormFactors(dge)

ggplot(counts_histogram, aes(x=counts * dge$samples$norm.factors)) + ylab("Absolute Frequency") + xlab("Normalized #reads") + geom_histogram(color="black", fill="white", position="dodge", bins=20, alpha=.5) + theme_classic()
@

We wanted to ensure that after normalisation the number of read counts we had for a sample was not a factor when analysing how the read counts of each gene affect the samples. We want to consider only the ratio between genes' read counts, not the number of read counts per sample.
To that end, we produced a MultiDimensional Scaling (MDS) plot where each mark corresponds to a sample, and the distance between samples corresponds to the leading Biological Coefficient of Variation (BCV), using the function \texttt{plotMDS}. 
In this plot, we coloured each mark according to the normalised read count of the respective sample, separating those that have a read count above the median (orange marks) from those that have it below the median (green marks). The result is shown in figure~\ref{fig:mds1}.
We can see that there is no apparent distinction between the green and orange marks, which shows our normalisation is successful: the read counts do not contribute to the main axes of variance.

Finally, we produced another MDS plot, this time to show the separation between normal and diseased tissue: we coloured the marks according to that classification.
The result can be seen in figure~\ref{fig:mds2}. There is a clear separation between the samples of normal tissues and the samples taken from tumours. It also appears that there are two distinct groups of samples from tumours: one more to the upper right corner of the plot, and another that takes over the bottom left half. We will analyse these two clusters in more detail on exercise~\ref{sec:2c}.

We can also see that there are a few normal-sample outliers: some orange marks are detached from the orange cluster. These are a cause for concern. A naive classifier might label them as diseased, causing a false positive. There are also a few green marks within the orange cluster, and these are even more preoccupying: they may be classified as healthy when they are in fact diseased. A false negative such as this may result in a patient declared healthy when they, in fact, have cancer, which means they will not be getting the treatment they need.

<<mds, fig.pos="ht", fig.width=5, fig.height=4, fig.align='center', fig.cap="Multidimensional Scaling plot of the data after normalizing.", fig.ncol=1, fig.subcap=c("a", "b", "c"), cache=TRUE>>=
normalized = colSums(read_counts) * dge$samples$norm.factors

par(mar=c(4.25,4.25,.75,.75))
plotMDS(dge, pch=20, col = brewer.pal(3, "Dark2")[as.numeric(normalized > median(normalized))+1], gene.selection = "common")
legend("topleft", legend=c("#reads <= median", "#reads > median"), col=brewer.pal(3, "Dark2"), fill=brewer.pal(3, "Dark2"), cex=0.8)

plotMDS(dge, pch=20, col = brewer.pal(3, "Dark2")[Tissue], gene.selection = "common")
legend("topleft", legend=c("Tumour Sample", "Normal Sample"), col=brewer.pal(3, "Dark2"), fill=brewer.pal(3, "Dark2"), cex=0.8)
@

\subsection{Phenotypic traits and genes that dominate variance}\label{sec:2c} % 2c) 
In an effort to separate the 2 different clusters formed by deceased tissue samples in the MDS plot in figure~\ref{fig:mds2}, we produced a new MDS plot evidencing the PAM50 classification of each sample, by colouring the respective mark with a different colour for each class. We can see that there is a clear distinction between the clusters. The upper right cluster corresponds to tissue samples with Basal classification, while the group on the bottom left is comprised of the Luminal type samples (both A and B). We can also see that the HER2-enriched samples are positioned ``in the middle'' of these two groups. Finally, there are too few normal-like samples to discern any pattern. We conclude that the PAM50 genes are associated with the main axes of variance.

\todo{Which phenotypic traits dominate data variance? Did you spot any non-biological batch effect worth acting on?}

<<mds-2, fig.pos="ht", fig.width=5, fig.height=4, fig.align='center', fig.cap="Multidimensional Scaling plot of the data after normalizing, grouped by PAM50 classification.", cache=TRUE>>=
par(mar=c(4.25,4.25,.75,.75))

plotMDS(dge, pch=20, col = brewer.pal(5, "Dark2")[PAM50], gene.selection = "common")
legend("topleft", legend=levels(PAM50), col=brewer.pal(5, "Dark2"), fill=brewer.pal(5, "Dark2"), cex=0.8)
@


\subsection{} % 2d)
\todo{What are the main differences in expressed genes and activated pathways between primary
tumours and normal breast samples? How does the age of patients affect those differences?}

<<2d, fig.pos="ht", fig.width=5, fig.height=4, fig.align='center', fig.cap="", cache=TRUE>>=
dge <- DGEList(counts=data.matrix(read_counts))
keep <- filterByExpr(dge)
dge <- dge[keep, , keep.lib.sizes=FALSE]
dge <- calcNormFactors(dge)

design <- model.matrix(~ Tissue)
v <- voom(dge,design,plot=TRUE)
linearfit = lmFit(v$E,design)
eBfit = eBayes(linearfit)
volcanoplot(eBfit,coef=2,style="B-statistic")
kable(topTable(eBfit,coef=2,number=5), format = "latex", booktabs = TRUE, caption = "My table", table.envir = "table*")

design <- model.matrix(~ Tissue + Age)
v <- voom(dge,design,plot=TRUE)
linearfit = lmFit(v$E,design)
eBfit = eBayes(linearfit)
volcanoplot(eBfit,coef=2,style="B-statistic")
kable(topTable(eBfit,coef=2,number=5), format = "latex", booktabs = TRUE, caption = "My table", table.envir = "table*")
@

\section{} % Group 3

\subsection{How well can genes recapitulate related immunohistochemistry tests} %3a)

We want to show how the gene expression for some genes relates to the binary classification for the related immunohistochemistry-based tests in the patient data. To do so, we produce 3 plots, showed in figures \ref{fig:estrogen}, \ref{fig:progesterone} and \ref{fig:her2}.

First, in figure~\ref{fig:estrogen1} we have a scatter tissue sample the read count of ESR1 on the x-axis and the read count of ERS2 on the y-axis. Each mark is colored according to the presence of estrogen receptors in the respective tissue sample. We can see by this graph that the expression of ESR1 is highly related to the presence of estrogen receptors: the tissue samples with estrogen receptors tend to have higher read counts of ESR1. On the other hand, ESR2 appears to have little influence on the presence of estrogen receptors. So we hypothesise that ERS1's expression is very good at recapitulating the presence of estrogen receptors in a tissue sample.

To confirm that hypothesis, we plotted a Receiver Operating Characteristic (ROC) curve. 
It plots the True Positive Rate (TPR) on the y-axis against the False Positive Rate (TNR) on the x-axis, and shows how the performance of a binary classifier varies as its discrimination threshold is varied.
A model has better accuracy at classifying samples (fewer false positives and false negatives) when the Area Under the Curve (AUC) value is higher, i.e., the curve is above and as far as possible from the \(y=x\) line. So, ideally, we want the curve to be as close as possible to upper left corner of the graph: All true positives, no false positives.
The ROC curve for read counts of ESR1 gene is shown in figure~\ref{fig:estrogen2}. We can see that this classifier it is possible to get TPR \(\approx 90\%\) and \(TNR \approx 10\%\) using this classifier, which adds up to a very good classification accuracy.

We conclude ERS1's expression is very good at recapitulating the presence of estrogen receptors in a tissue sample, but the same is not true of ESR2.

<<estrogen, fig.pos='ht', fig.width=4, fig.height=3.5, fig.ncol=1, fig.align='center', fig.cap="Relation between ESR1/ESR2 expression and the presence of estrogen receptors.", fig.subcap=c('a', 'b'), warning=FALSE>>=
ggplot(data_g3, aes(x=ESR1, y=ESR2, color=Estrogen)) + scale_color_brewer(palette="Dark2") + scale_y_log10() + scale_x_log10() + geom_point() + annotation_logticks() + theme_classic() + theme(legend.position="top")

tmp <- ggplot(data.frame(pred=ESR1[!is.na(Estrogen_bin)], truth=Estrogen_bin[!is.na(Estrogen_bin)]), aes(m=pred, d=truth)) + geom_roc(n.cuts=5) + geom_abline(color="black")

tmp + style_roc(theme=theme_classic) + annotate("text", x=.75, y=.25, label=paste("AUC =", round(calc_auc(tmp)$AUC, 2))) #+ theme(panel.grid.major.y = element_line(colour = "grey", size = .25), panel.grid.minor.y = element_line(colour = "grey", size = .1), panel.grid.major.x = element_line(colour = "grey", size = .25), panel.grid.minor.x = element_line(colour = "grey", size = .1))
@

Secondly, in figure~\ref{fig:progesterone1} we want to evaluate how PGR relates to the presence of progesterone receptors in tissue samples. Since we only have one gene to evaluate, we adopt a different approach: we used a histogram to plot the number of tissue samples we have (in the y-axis) against the read count of PGR. As we can see, the trend is for the tissue samples that test positive for the presence of progesterone receptors to have a higher read count of PGR, and for the the negative samples to have lower values.

Again, we plotted a ROC curve shown in figure~\ref{fig:progesterone2}, this time showing how well the read counts of PGR's expression classifies samples the presence of progesterone receptors in tissue samples. This time, the curve does not come as close to the upper left corner as with ESR1. However we can maintain the TPR as high as 90\% maintaining the FPR at 25\%. We still have AUC = 0.9, so we conclude PGR's expression is very good at recapitulating the presence of progesterone receptors in a tissue sample.

<<progesterone, fig.pos='ht', fig.width=4, fig.height=3.5, fig.ncol=1, fig.align='center', fig.cap="Relation between PGR expression and the presence of progesterone receptors.", fig.subcap=c('a', 'b'), warning=FALSE>>=
gghistogram(data_g3, x = "PGR", bins = 20,
            add = "mean", rug = TRUE,
            color = "Progesterone", fill="Progesterone", xscale="log10", palette="Dark2")

tmp <- ggplot(data.frame(pred=PGR[!is.na(Progesterone_bin)], truth=Progesterone_bin[!is.na(Progesterone_bin)]), aes(m=pred, d=truth)) + geom_roc(n.cuts=5) + geom_abline(color="black")

tmp + style_roc(theme=theme_classic) + annotate("text", x=.75, y=.25, label=paste("AUC =", round(calc_auc(tmp)$AUC, 2))) #+ theme(panel.grid.major.y = element_line(colour = "grey", size = .25), panel.grid.minor.y = element_line(colour = "grey", size = .1), panel.grid.major.x = element_line(colour = "grey", size = .25), panel.grid.minor.x = element_line(colour = "grey", size = .1))
@

Finally, in figure~\ref{fig:her2} we use a similar histogram to show the relation between the presence of HER2 protein in the tissue sample to the read count of ERBB2 gene, as well as the usual ROC curve.

ERBB2's expressivity is not a very good indicator of the presence of HER2 protein in the sample. The AUC is now 0.77 wich is well below the other two values. We can see that we can keep a very low FPF, less than 5\%, but we always have a very unsatisfactory TPR, aroung 50\%. This means that using ERBB2's expressivity alone to classify, samples that test positive for HER2 protein will be classified as positive with the same probability that they will be classified negative: the classifier is wrong 50\% of the time. However, samples that test negative for HER2 protein will be classified as negative 95\% of the time.

We conclude that another measure must be used to complement a classifier for the presence of HER2 protein on tissue samples, perhaps the expressivity of another gene. If a ERBB2-based classifier is used, we should be careful when handling its results. If it classifies a sample as `positive', we can safely trust that result, as it has only 5\% chance of being wrong; on the other hand, if the classifier returns `negative', we should not trust it because our classifier classifies half the positive samples as `negative'.

<<her2, fig.pos='ht', fig.width=4, fig.height=3.5, fig.ncol=1, fig.align='center', fig.cap="Relation between ERBB2 expression and the presence of HER2 protein.", fig.subcap=c('a', 'b'), warning=FALSE>>=
gghistogram(data_g3, x = "ERBB2", bins = 20,
            add = "mean", rug = TRUE,
            color = "HER2", fill = "HER2", xscale="log10", palette="Dark2")

tmp <- ggplot(data.frame(pred=ERBB2[!is.na(HER2_bin)], truth=HER2_bin[!is.na(HER2_bin)]), aes(m=pred, d=truth)) + geom_roc(n.cuts=5) + geom_abline(color="black")

tmp + style_roc(theme=theme_classic) + annotate("text", x=.75, y=.25, label=paste("AUC =", round(calc_auc(tmp)$AUC, 2))) #+ theme(panel.grid.major.y = element_line(colour = "grey", size = .25), panel.grid.minor.y = element_line(colour = "grey", size = .1), panel.grid.major.x = element_line(colour = "grey", size = .25), panel.grid.minor.x = element_line(colour = "grey", size = .1))
@

\FloatBarrier
\subsection{Survival analysis} %3b)
First, we produced a typical survival analysis plot, shown in figure~\ref{fig:survival}.

<<survival, fig.pos="ht", fig.asp=1/2, fig.align='center', fig.cap="Hello">>=
time <- ifelse(is.na(DaysToDeath), LastFollowUp, DaysToDeath)

data = data.frame(Patient, Status, PAM50, DaysToDeath)

km_fit <- survfit(Surv(time, !is.na(DaysToDeath)) ~ PAM50, data=data)
autoplot(km_fit, conf.int.alpha=0.1, ylab="survival", xlab="time (days)")+ scale_color_brewer(palette="Dark2") + scale_fill_brewer(palette="Dark2") + theme_classic()
@

This plot shows the probability of a patient surviving past a certain number of days depending on the sample's PAM50 classification. Analysing this plot, we conclude that Normal-like classification patients have the worst diagnosis: in this dataset, none survived past 2000 days. The second worst scenario is Luminal B: no patient suvived for longer than 4000 days after diagnosis, and only 25 \% suvived passt 2500 days. In \nth{3} place, we have HER2-enriched patients. Of these, around 70\% live up to 3000 days, but only around 30\% go past that date. Then, in \nth{4} place, we have patients with Luminal A type samples. These show a linear survival probability decay from day 0 to day 4500. By day 4500, only around 30-35\% are expected to have survived. Finally, the best prognostic is Basal-like. For these patients, we have again a approximately linear decay in survival until it hits 55\% at around 2500 days after diagnosal. After that, our data shows a survival rate past 7000 days of around 55\%.

However, these results should be taken with a grain of salt. We can see that we have very large confidence intervals for most classes, which tell us we do not have enough data to make conclusive predictions, possibily due to the large amount of censored data. 

\subsection{Gene signature that best classifies molecular subtypes} %3c)

<<fig.pos="ht", fig.align='center', fig.cap="Hello">>=
dge <- DGEList(counts=data.matrix(read_counts))
keep <- filterByExpr(dge)
dge <- dge[keep, , keep.lib.sizes=FALSE]
dge <- calcNormFactors(dge)

design <- model.matrix(~ addNA(PAM50))

v <- voom(dge,design,plot=TRUE)
linearfit = lmFit(v$E,design)
eBfit = eBayes(linearfit)
volcanoplot(eBfit,coef=2,style="B-statistic")
@

<<fig.pos="ht", fig.align='center', fig.env="figure*", fig.cap="Hello">>=
kable(topTable(eBfit,coef=2,number=5), format = "latex", booktabs = TRUE, caption = "My table", table.envir = "table*")
@

\subsection{Classifying molecular subtype} %3d)

<<classifier, fig.pos="ht", fig.width=5, fig.height=4, fig.align='center', fig.cap="a", cache=TRUE, message=FALSE>>=
top_genes <- rownames(topTable(eBfit, number=5))

reads <- as.data.frame(t(read_counts[top_genes,]))
reads$PAM50 <- PAM50
labeled <- reads[!is.na(PAM50),]
unlabeled <- reads[is.na(PAM50),]

results <- knn.cv(labeled[, names(labeled) != "PAM50"], cl=labeled$PAM50, k=5)

ggplot(data = melt(confusionMatrix(results, labeled$PAM50)$table), aes(x=Prediction, y=Reference, fill=value)) + geom_tile() + scale_fill_gradient(trans="sqrt") + theme(axis.text.x = element_text(angle = 45, margin=margin(25,0,0,0)))

@

<<classifier-2, fig.pos="ht", fig.width=5, fig.height=4, fig.align='center', fig.cap="a", cache=TRUE>>=
results <- knn(labeled[, names(labeled) != "PAM50"], unlabeled[, names(unlabeled) != "PAM50"], cl=labeled$PAM50, k=5)

final_dge <- dge[,c(rownames(labeled), rownames(unlabeled))]
final_labels <- unlist(list(labeled$PAM50, results))

par(mar=c(4.25,4.25,.75,.75))
plotMDS(final_dge, pch=20, col = brewer.pal(5, "Dark2")[final_labels], gene.selection = "common")
legend("topleft", legend=levels(final_labels), col=brewer.pal(5, "Dark2"), fill=brewer.pal(5, "Dark2"), cex=0.8)
@

\end{document}
